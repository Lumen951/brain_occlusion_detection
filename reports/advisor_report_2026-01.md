# 脑遮挡检测项目阶段性进展报告

**汇报日期：** 2026年1月9日
**项目名称：** 遮挡条件下人类与AI视觉识别策略对比研究
**研究阶段：** Phase 1-3 基线实验完成

---

## 一、研究背景与动机

### 1.1 核心研究问题

在真实视觉场景中，遮挡是普遍存在的挑战。人类视觉系统能够在高度遮挡条件下保持较好的识别能力，但深度学习模型在这方面的表现尚不明确。本研究旨在回答：

1. **人类与AI在遮挡条件下的性能差距有多大？**
2. **不同深度学习架构（Transformer vs CNN）对遮挡的鲁棒性是否存在差异？**
3. **能否通过神经科学方法（fMRI）验证AI模型的视觉处理机制？**
4. **如何设计创新算法缩小人机性能差距？**

### 1.2 研究意义

- **理论价值：** 揭示人类视觉系统处理遮挡信息的机制，为计算神经科学提供实证数据
- **应用价值：** 提升AI在遮挡场景（自动驾驶、医学影像、安防监控）的鲁棒性
- **方法创新：** 结合行为实验、深度学习与神经影像，构建多模态验证框架

---

## 二、实验设计

### 2.1 数据集：OIID (Occluded Image Interpretation Dataset)

- **来源：** OpenNeuro (ds005226)
- **任务：** 二分类任务（Aircraft1 vs Aircraft2）
- **遮挡等级：** 10%, 70%, 90%
- **数据划分：**
  - 训练集：300张图像
  - 验证集：1,584张图像
  - 测试集：48张图像（每个遮挡等级16张）

### 2.2 人类基线数据

- **被试数量：** 65名健康成年人
- **试次总数：** 19,500次试验（65人 × 300张图像）
- **记录数据：** 准确率、反应时间、逐图像表现

### 2.3 AI模型架构

| 模型 | 架构类型 | 参数量 | 预训练数据 | 训练策略 |
|------|---------|--------|-----------|---------|
| **ViT-B/16** | Vision Transformer | 86M | ImageNet-21k | Freeze backbone + 分类头微调 |
| **ResNet-50** | 残差卷积网络 | 25M | ImageNet-1k | Freeze backbone + 分类头微调 |
| **MAE-ViT** | 自监督预训练ViT | 86M | ImageNet-1k (MAE) | 多阶段微调 |

**正则化策略：**
- Freeze backbone（冻结主干网络，仅训练分类头）
- 数据增强（旋转、仿射变换、颜色抖动）
- Dropout (0.5) + Weight Decay (0.2)
- 学习率：3e-5，余弦退火调度

---

## 三、核心实验结果

### 3.1 人类 vs AI 性能对比

#### **人类表现（65名被试平均）**

| 遮挡等级 | 准确率 | 平均反应时间 | 试次数 |
|---------|--------|-------------|--------|
| **10%** | **95.62%** | ~1200ms | 6,500 |
| **70%** | **79.28%** | ~1800ms | 6,500 |
| **90%** | **61.88%** | ~2200ms | 6,500 |

**关键发现：**
- 人类在低遮挡条件下接近完美表现（95.62%）
- 即使在90%高遮挡条件下，人类仍保持61.88%的准确率
- 反应时间随遮挡增加而延长，反映认知负荷增加

---

#### **AI模型表现（测试集48张图像）**

##### **ViT-B/16 (Vision Transformer)**

| 遮挡等级 | 准确率 | Precision | Recall | F1 Score |
|---------|--------|-----------|--------|----------|
| **10%** | 50.0% | 50.0% | 25.0% | 0.333 |
| **70%** | 50.0% | 50.0% | 50.0% | 0.500 |
| **90%** | **56.25%** | 53.3% | **100.0%** | **0.696** |

##### **ResNet-50 (卷积神经网络)**

| 遮挡等级 | 准确率 | Precision | Recall | F1 Score |
|---------|--------|-----------|--------|----------|
| **10%** | 43.75% | 45.5% | 62.5% | 0.526 |
| **70%** | 43.75% | 0.0% | 0.0% | 0.000 |
| **90%** | 50.0% | 0.0% | 0.0% | 0.000 |

---

### 3.2 人机性能差距量化

#### **准确率差距（Gap = Human - AI）**

| 遮挡等级 | 人类准确率 | ViT准确率 | ResNet准确率 | ViT Gap | ResNet Gap |
|---------|-----------|----------|-------------|---------|-----------|
| **10%** | 95.62% | 50.0% | 43.75% | **45.62%** | **51.87%** |
| **70%** | 79.28% | 50.0% | 43.75% | **29.28%** | **35.53%** |
| **90%** | 61.88% | 56.25% | 50.0% | **5.63%** | **11.88%** |

**关键洞察：**

1. **巨大的性能鸿沟：** AI模型在所有遮挡等级下均显著低于人类表现
   - 低遮挡（10%）：差距高达45-52个百分点
   - 中遮挡（70%）：差距约30-36个百分点
   - 高遮挡（90%）：差距缩小至6-12个百分点

2. **架构差异：**
   - **ViT在高遮挡条件下表现更好**（90%: F1=0.696 vs ResNet F1=0.0）
   - ResNet在70%和90%遮挡下完全失效（F1=0.0）
   - ViT的全局注意力机制可能更适合处理遮挡信息

3. **反直觉现象：**
   - AI模型在低遮挡条件下表现反而更差
   - 可能原因：小样本过拟合、训练数据分布偏差

---

### 3.3 逐图像一致性分析

我们分析了48张测试图像上人类、ViT和ResNet的预测一致性：

| 一致性类型 | 图像数量 | 占比 |
|-----------|---------|------|
| **三者全对** | 2张 | 4.2% |
| **三者全错** | 0张 | 0% |
| **仅人类正确** | 多数 | >60% |
| **AI正确但人类错误** | 极少 | <5% |

**示例分析：**

- `Aircraft1_10%_44.jpg` 和 `Aircraft2_10%_22.jpg`：三者全部正确
- `Aircraft1_10%_35.jpg`：人类正确，ViT和ResNet均错误
- `Aircraft2_10%_15.jpg`：人类正确，两个AI模型均错误

**结论：** AI模型的错误模式与人类显著不同，暗示其使用了不同的视觉特征提取策略。

---

### 3.4 训练动态分析

#### **ViT-B/16 训练曲线**
- 训练轮次：15 epochs
- 最佳验证准确率：~52%
- 早停触发：验证损失不再下降

#### **ResNet-50 训练曲线**
- 训练轮次：14 epochs
- 最佳验证准确率：~48%
- 过拟合现象：训练准确率高于验证准确率

#### **MAE-ViT 多阶段训练**
- Stage 1: 37 epochs（自监督预训练特征微调）
- Stage 2-3: 渐进式解冻训练
- 性能提升有限，仍未达到人类水平

**问题诊断：**
- 小样本数据（300张训练图像）导致严重过拟合
- Freeze backbone策略虽缓解过拟合，但限制了模型学习能力
- 数据增强和正则化未能根本解决泛化问题

---

## 四、当前挑战与问题

### 4.1 技术挑战

1. **小样本学习困境**
   - 训练数据仅300张，难以支撑大模型训练
   - 数据增强效果有限，无法覆盖真实遮挡场景的多样性

2. **泛化能力不足**
   - 模型在测试集上接近随机猜测（~50%）
   - 高遮挡条件下ResNet完全失效

3. **特征提取机制不明**
   - 不清楚AI模型关注图像的哪些区域
   - 缺乏可解释性分析（注意力图、显著性图）

### 4.2 理论问题

1. **人机差距的根源是什么？**
   - 人类是否使用了先验知识（飞机的整体形状、部件关系）？
   - AI模型是否过度依赖局部纹理而非全局结构？

2. **架构差异的本质**
   - 为什么ViT在高遮挡下优于ResNet？
   - Transformer的全局注意力机制是否更接近人类视觉？

3. **如何验证AI模型的神经合理性？**
   - 能否通过fMRI数据验证模型的中间表征与人脑视觉皮层的相似性？

---

## 五、下一步研究方向（需导师建议）

### 方向一：扩展模型架构对比（Phase 2）

**目标：** 验证架构差异是否具有普遍性

**候选模型：**
- **Swin Transformer**（层次化Transformer）
- **ConvNeXt**（现代化CNN）
- **DeiT**（数据高效Transformer）
- **Hybrid模型**（CNN + Transformer）

**预期收益：**
- 更全面的架构对比
- 识别最适合遮挡场景的架构特性

**风险：**
- 小样本问题依然存在
- 可能无法显著提升性能

---

### 方向二：神经科学验证（fMRI整合）⭐ **推荐**

**核心思路：** 将AI模型的中间表征与人脑fMRI信号进行对比，验证模型的神经合理性

#### **具体方案：**

1. **表征相似性分析（RSA）**
   - 提取AI模型各层的特征表征（如ViT的12层Transformer块）
   - 提取人脑视觉通路的fMRI信号（V1, V2, V4, IT皮层）
   - 计算表征相似性矩阵（RDM），评估AI与人脑的对应关系

2. **编码模型（Encoding Model）**
   - 使用AI模型特征预测fMRI信号
   - 评估哪些模型层最能解释人脑活动

3. **解码模型（Decoding Model）**
   - 从fMRI信号重建图像或预测类别
   - 对比AI模型与人脑的解码准确率

#### **预期成果：**
- 发现AI模型与人脑视觉处理的相似性和差异
- 识别哪些架构更接近人类视觉机制
- 为改进AI模型提供神经科学依据

#### **数据需求：**
- OIID数据集已包含fMRI数据（需确认可用性）
- 如无fMRI数据，可考虑使用公开数据集（如NSD, BOLD5000）

#### **技术挑战：**
- fMRI数据预处理（去噪、配准、ROI提取）
- 跨模态对齐（图像 → fMRI → AI特征）
- 统计显著性检验

---

### 方向三：创新算法设计 ⭐ **推荐**

**核心思路：** 设计专门针对遮挡场景的算法，缩小人机性能差距

#### **候选方案：**

##### **3.1 遮挡感知注意力机制（Occlusion-Aware Attention）**

**动机：** 人类能够主动忽略遮挡区域，聚焦于可见部分

**实现：**
- 设计遮挡检测模块，自动识别遮挡区域
- 在注意力计算中降低遮挡区域的权重
- 增强可见区域的特征表达

**技术路线：**
```
输入图像 → 遮挡掩码预测 → 加权注意力 → 分类
```

##### **3.2 部件感知模型（Part-Based Model）**

**动机：** 人类识别物体时依赖部件关系（如飞机的机翼、机身、尾翼）

**实现：**
- 预训练部件检测器（如机翼检测器）
- 即使部分部件被遮挡，仍可通过可见部件推断
- 使用图神经网络建模部件关系

**技术路线：**
```
输入图像 → 部件检测 → 部件关系图 → GNN推理 → 分类
```

##### **3.3 对比学习 + 数据增强（Contrastive Learning）**

**动机：** 通过自监督学习增强模型对遮挡的鲁棒性

**实现：**
- 使用SimCLR或MoCo框架
- 设计遮挡增强策略（随机遮挡、cutout、mixup）
- 学习遮挡不变的特征表征

**技术路线：**
```
大规模无标注数据 → 对比学习预训练 → 下游微调
```

##### **3.4 元学习（Meta-Learning）**

**动机：** 小样本场景下快速适应新任务

**实现：**
- 使用MAML或Prototypical Networks
- 在多个相关任务上预训练（如不同遮挡等级）
- 快速适应目标任务

---

### 方向四：数据扩充策略

**问题：** 当前训练数据仅300张，严重限制模型性能

**候选方案：**

1. **合成数据生成**
   - 使用3D飞机模型渲染不同视角和遮挡
   - 使用生成对抗网络（GAN）生成遮挡图像

2. **迁移学习**
   - 在大规模遮挡数据集（如MS-COCO with occlusion）上预训练
   - 迁移到OIID数据集

3. **跨数据集泛化**
   - 收集其他飞机识别数据集
   - 评估模型的跨数据集泛化能力

---

## 六、需要导师建议的关键问题

### 6.1 研究方向选择

**问题1：** 在以下方向中，您认为哪个最有价值？

- [ ] **方向二（fMRI验证）**：理论创新强，但技术难度高
- [ ] **方向三（创新算法）**：实用价值高，但可能缺乏理论深度
- [ ] **方向四（数据扩充）**：工程性强，但创新性有限
- [ ] **组合方向**：如"fMRI验证 + 创新算法"

**问题2：** 如果选择fMRI验证，您是否有相关资源或合作者？

---

### 6.2 论文发表规划

**问题3：** 基于当前进展，您认为适合投稿的会议/期刊是？

**候选目标：**
- **顶会：** NeurIPS, ICCV, CVPR（需要更强的理论创新）
- **神经科学期刊：** NeuroImage, Journal of Neuroscience（需要fMRI数据）
- **交叉领域：** Nature Communications, PLOS Computational Biology

**问题4：** 您认为当前工作的核心贡献应该是什么？
- [ ] 揭示人机视觉差距的量化分析
- [ ] 提出新的遮挡鲁棒算法
- [ ] 建立AI-fMRI验证框架
- [ ] 综合性对比研究

---

### 6.3 时间与资源规划

**问题5：** 您建议的研究时间线是？
- 短期（1-2个月）：完成当前Phase 2架构对比
- 中期（3-6个月）：实现创新算法并验证
- 长期（6-12个月）：整合fMRI数据，完成完整研究

**问题6：** 是否有计算资源支持？
- 当前实验使用单GPU（RTX 3090级别）
- 如需大规模实验（如对比学习预训练），需要多GPU集群

---

## 七、总结

### 7.1 已完成工作

✅ 完成Phase 1-3基线实验（ViT, ResNet, MAE-ViT）
✅ 量化人机性能差距（最大差距51.87%）
✅ 发现架构差异（ViT在高遮挡下优于ResNet）
✅ 建立完整的实验流程和分析工具

### 7.2 核心发现

1. **AI模型在遮挡场景下显著弱于人类**（差距5-52个百分点）
2. **Transformer架构在高遮挡条件下表现更好**
3. **小样本过拟合是当前主要瓶颈**
4. **AI与人类的错误模式不同**，暗示不同的视觉策略

### 7.3 下一步重点

**推荐优先级：**

1. **优先级1：** fMRI验证 + 创新算法（理论与实践结合）
2. **优先级2：** 部件感知模型或遮挡感知注意力（针对性强）
3. **优先级3：** 扩展架构对比（补充实验）

---

## 八、附录

### 8.1 可视化资源

所有实验结果的可视化图表已生成，位于：
- `experiments/analysis/all_visualizations/`（训练曲线、性能对比）
- `experiments/analysis/human_vs_ai_performance.png`（人机对比）
- `experiments/analysis/per_image_agreement_analysis.png`（一致性分析）

### 8.2 数据文件

- 人类数据：`data/human_performance/`
- AI预测：`experiments/analysis/*_test_predictions.csv`
- 逐图像对比：`experiments/analysis/per_image_comparison_summary.csv`

### 8.3 代码仓库

- 训练脚本：`scripts/training/train_model.py`
- 评估脚本：`scripts/evaluation/evaluate_by_occlusion.py`
- 分析脚本：`scripts/analysis/`

---

**期待您的指导和建议！**
