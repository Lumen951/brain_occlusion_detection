# æ•°æ®æ‰©å……å¿«é€Ÿå¼€å§‹æŒ‡å—

**ç›®æ ‡**: ä»300å¼ åŸå§‹å›¾ç‰‡ç”Ÿæˆ10,000å¼ è®­ç»ƒå›¾ç‰‡

---

## ğŸ“‹ å‡†å¤‡å·¥ä½œ

### 1. ç¡®è®¤ç¯å¢ƒ

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ (éœ€è¦3.7+)
python --version

# å®‰è£…ä¾èµ–
pip install pillow numpy tqdm
```

### 2. ç¡®è®¤è·¯å¾„

**åŸå§‹å›¾ç‰‡**: `e:\Dataset\ds005226\derivatives\stimuli_dataset\stimuli_original`
- åº”è¯¥åŒ…å«300å¼ å›¾ç‰‡
- æ–‡ä»¶åæ ¼å¼: `Aircraft{1|2}_{10|70|90}%_{id}_original.jpg`

**è¾“å‡ºç›®å½•**: `d:\University\Junior\1st\code\brain_occlusion_detection\data`

---

## ğŸš€ æ‰§è¡Œæ­¥éª¤

### Step 1: æ•°æ®å¢å¼º (ç”Ÿæˆ~10,000å¼ å¢å¼ºå›¾ç‰‡)

```bash
cd d:\University\Junior\1st\code\brain_occlusion_detection

python scripts/data_preparation/augment_dataset.py \
  --input-dir "e:\Dataset\ds005226\derivatives\stimuli_dataset\stimuli_original" \
  --output-dir "data/augmented_images" \
  --num-augmentations 33 \
  --seed 42
```

**é¢„è®¡æ—¶é—´**: 10-15åˆ†é’Ÿ
**è¾“å‡º**: `data/augmented_images/` (çº¦9,900å¼ å›¾ç‰‡)

**æ£€æŸ¥ç‚¹**:
```bash
# æ£€æŸ¥ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
ls data/augmented_images | wc -l
# åº”è¯¥æ˜¾ç¤º: 9900 (300 Ã— 33)

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
cat data/augmented_images/augmentation_stats.json
```

### Step 2: æ·»åŠ é®æŒ¡ (ä¸ºå¢å¼ºå›¾ç‰‡æ·»åŠ éšæœºé®æŒ¡)

```bash
python scripts/data_preparation/add_occlusion.py \
  --input-dir "data/augmented_images" \
  --output-dir "data/train_augmented" \
  --mask-size 10 \
  --seed 42
```

**é¢„è®¡æ—¶é—´**: 15-20åˆ†é’Ÿ
**è¾“å‡º**: `data/train_augmented/` (çº¦9,900å¼ å¸¦é®æŒ¡çš„å›¾ç‰‡)

**æ£€æŸ¥ç‚¹**:
```bash
# æ£€æŸ¥ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
ls data/train_augmented | wc -l
# åº”è¯¥æ˜¾ç¤º: 9900

# æŸ¥çœ‹é®æŒ¡ç»Ÿè®¡
cat data/train_augmented/occlusion_stats.json
```

### Step 3: åˆ’åˆ†æ•°æ®é›† (è®­ç»ƒé›† vs éªŒè¯é›†)

```bash
python scripts/data_preparation/split_dataset.py \
  --original-dir "e:\Dataset\ds005226\derivatives\stimuli_dataset\stimuli_original" \
  --augmented-dir "data/train_augmented" \
  --train-dir "data/train" \
  --val-dir "data/val"
```

**é¢„è®¡æ—¶é—´**: 2-3åˆ†é’Ÿ
**è¾“å‡º**:
- `data/train/` (9,900å¼ å¢å¼ºå›¾ç‰‡)
- `data/val/` (300å¼ åŸå§‹å›¾ç‰‡)

**æ£€æŸ¥ç‚¹**:
```bash
# æ£€æŸ¥è®­ç»ƒé›†
ls data/train | wc -l
# åº”è¯¥æ˜¾ç¤º: 9900

# æ£€æŸ¥éªŒè¯é›†
ls data/val | wc -l
# åº”è¯¥æ˜¾ç¤º: 300

# æŸ¥çœ‹æ•°æ®é›†ç»Ÿè®¡
cat data/dataset_split_stats.json
```

---

## âœ… éªŒè¯ç»“æœ

### 1. æ£€æŸ¥æ•°æ®é›†å¹³è¡¡æ€§

```python
import json

# è¯»å–ç»Ÿè®¡ä¿¡æ¯
with open('data/dataset_split_stats.json', 'r') as f:
    stats = json.load(f)

# è®­ç»ƒé›†
print("è®­ç»ƒé›†:")
print(f"  æ€»è®¡: {stats['train']['total']}")
print(f"  Aircraft1: {stats['train']['by_class']['Aircraft1']}")
print(f"  Aircraft2: {stats['train']['by_class']['Aircraft2']}")
print(f"  10%é®æŒ¡: {stats['train']['by_occlusion']['10%']}")
print(f"  70%é®æŒ¡: {stats['train']['by_occlusion']['70%']}")
print(f"  90%é®æŒ¡: {stats['train']['by_occlusion']['90%']}")

# éªŒè¯é›†
print("\néªŒè¯é›†:")
print(f"  æ€»è®¡: {stats['val']['total']}")
print(f"  Aircraft1: {stats['val']['by_class']['Aircraft1']}")
print(f"  Aircraft2: {stats['val']['by_class']['Aircraft2']}")
print(f"  10%é®æŒ¡: {stats['val']['by_occlusion']['10%']}")
print(f"  70%é®æŒ¡: {stats['val']['by_occlusion']['70%']}")
print(f"  90%é®æŒ¡: {stats['val']['by_occlusion']['90%']}")
```

**é¢„æœŸè¾“å‡º**:
```
è®­ç»ƒé›†:
  æ€»è®¡: 9900
  Aircraft1: 4950
  Aircraft2: 4950
  10%é®æŒ¡: 3300
  70%é®æŒ¡: 3300
  90%é®æŒ¡: 3300

éªŒè¯é›†:
  æ€»è®¡: 300
  Aircraft1: 150
  Aircraft2: 150
  10%é®æŒ¡: 100
  70%é®æŒ¡: 100
  90%é®æŒ¡: 100
```

### 2. å¯è§†åŒ–æ£€æŸ¥

```python
from PIL import Image
import matplotlib.pyplot as plt

# éšæœºé€‰æ‹©å‡ å¼ å›¾ç‰‡æŸ¥çœ‹
import random

train_images = list(Path('data/train').glob('*.jpg'))
val_images = list(Path('data/val').glob('*.jpg'))

# æ˜¾ç¤ºè®­ç»ƒé›†æ ·æœ¬
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('è®­ç»ƒé›†æ ·æœ¬ (å¢å¼º+é®æŒ¡)')

for i, ax in enumerate(axes.flat):
    img_path = random.choice(train_images)
    img = Image.open(img_path)
    ax.imshow(img)
    ax.set_title(img_path.name, fontsize=8)
    ax.axis('off')

plt.tight_layout()
plt.savefig('data/train_samples.png', dpi=150)
print("è®­ç»ƒé›†æ ·æœ¬å·²ä¿å­˜åˆ°: data/train_samples.png")

# æ˜¾ç¤ºéªŒè¯é›†æ ·æœ¬
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
fig.suptitle('éªŒè¯é›†æ ·æœ¬ (åŸå§‹å›¾ç‰‡)')

for i, ax in enumerate(axes.flat):
    img_path = random.choice(val_images)
    img = Image.open(img_path)
    ax.imshow(img)
    ax.set_title(img_path.name, fontsize=8)
    ax.axis('off')

plt.tight_layout()
plt.savefig('data/val_samples.png', dpi=150)
print("éªŒè¯é›†æ ·æœ¬å·²ä¿å­˜åˆ°: data/val_samples.png")
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: æ‰¾ä¸åˆ°åŸå§‹å›¾ç‰‡

**é”™è¯¯**: `æ‰¾åˆ° 0 å¼ åŸå§‹å›¾ç‰‡`

**è§£å†³**:
```bash
# æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®
ls "e:\Dataset\ds005226\derivatives\stimuli_dataset\stimuli_original" | head -5

# å¦‚æœè·¯å¾„ä¸å¯¹,ä¿®æ”¹å‘½ä»¤ä¸­çš„ --input-dir å‚æ•°
```

### é—®é¢˜2: å†…å­˜ä¸è¶³

**é”™è¯¯**: `MemoryError`

**è§£å†³**:
```bash
# å‡å°‘æ¯å¼ å›¾ç‰‡çš„å¢å¼ºæ•°é‡
python scripts/data_preparation/augment_dataset.py \
  --num-augmentations 20  # ä»33å‡å°‘åˆ°20
```

### é—®é¢˜3: ç”Ÿæˆé€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–**:
- å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜
- ä½¿ç”¨SSDå­˜å‚¨è¾“å‡ºæ–‡ä»¶
- å‡å°‘å¢å¼ºæ•°é‡

### é—®é¢˜4: å›¾ç‰‡è´¨é‡ä¸‹é™

**æ£€æŸ¥**:
```python
# å¯¹æ¯”åŸå§‹å›¾ç‰‡å’Œå¢å¼ºå›¾ç‰‡
from PIL import Image

original = Image.open('e:/Dataset/ds005226/derivatives/stimuli_dataset/stimuli_original/Aircraft1_10%_1_original.jpg')
augmented = Image.open('data/augmented_images/Aircraft1_10%_1_aug0.jpg')

# æ˜¾ç¤ºå¯¹æ¯”
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(original)
axes[0].set_title('Original')
axes[1].imshow(augmented)
axes[1].set_title('Augmented')
plt.show()
```

**è°ƒæ•´**: å¦‚æœè´¨é‡ä¸‹é™æ˜æ˜¾,ä¿®æ”¹ `augment_dataset.py` ä¸­çš„å˜æ¢å‚æ•°

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ•°æ®é›†è§„æ¨¡å¯¹æ¯”

| æ•°æ®é›† | ä¹‹å‰ | ä¹‹å | å¢é•¿ |
|--------|------|------|------|
| è®­ç»ƒé›† | 210 | 9,900 | 47Ã— |
| éªŒè¯é›† | 42 | 300 | 7Ã— |
| æ€»è®¡ | 252 | 10,200 | 40Ã— |

### é¢„æœŸæ€§èƒ½æå‡

åŸºäºæ–‡çŒ®å’Œç»éªŒ:

| æ¨¡å‹ | å½“å‰æ€§èƒ½ | é¢„æœŸæ€§èƒ½ | æå‡ |
|------|----------|----------|------|
| ViT-B/16 | 52% | 70-80% | +18-28% |
| ResNet-50 | 46% | 65-75% | +19-29% |
| MAE-ViT | - | 75-85% | æ–°æ¨¡å‹ |

---

## ğŸ¯ ä¸‹ä¸€æ­¥

æ•°æ®é›†ç”Ÿæˆå®Œæˆå:

### 1. æ›´æ–°é…ç½®æ–‡ä»¶

ç¡®ä¿è®­ç»ƒé…ç½®æŒ‡å‘æ–°çš„æ•°æ®é›†:

```yaml
# configs/vit_b16_image_split.yaml
dataset:
  type: "image_split"
  train_dir: "data/train"  # 9,900å¼ å¢å¼ºå›¾ç‰‡
  val_dir: "data/val"      # 300å¼ åŸå§‹å›¾ç‰‡
  test_dir: ""             # ä¸ä½¿ç”¨æµ‹è¯•é›†
```

### 2. é‡æ–°è®­ç»ƒæ¨¡å‹

```bash
# ViT-B/16
python scripts/training/train_model.py --config configs/vit_b16_image_split.yaml

# ResNet-50
python scripts/training/train_model.py --config configs/resnet50_image_split.yaml

# MAE-ViT (å¦‚æœå·²å®ç°)
python scripts/training/train_model.py --config configs/mae_vit_base.yaml
```

### 3. è¯„ä¼°æ€§èƒ½

```bash
# è¯„ä¼°æ¨¡å‹
python scripts/evaluation/evaluate_by_occlusion.py \
  --checkpoint experiments/vit_b16/image_split/checkpoints/best_model.pth \
  --config configs/vit_b16_image_split.yaml

# å¯¹æ¯”æ–°æ—§æ•°æ®é›†çš„æ•ˆæœ
python scripts/analysis/compare_experiments.py
```

---

## ğŸ“ éœ€è¦å¸®åŠ©?

å¦‚æœé‡åˆ°é—®é¢˜:
1. æ£€æŸ¥ `data/augmented_images/augmentation_stats.json`
2. æ£€æŸ¥ `data/train_augmented/occlusion_stats.json`
3. æ£€æŸ¥ `data/dataset_split_stats.json`
4. å‚è€ƒ `docs/DATA_AUGMENTATION_PLAN.md` çš„è¯¦ç»†è¯´æ˜

---

**åˆ›å»ºæ—¥æœŸ**: 2026-01-08
**é¢„è®¡æ€»æ—¶é—´**: 30-40åˆ†é’Ÿ
**é¢„è®¡å­˜å‚¨ç©ºé—´**: ~200MB
