# MAE ViT-B/16 Stage 1: Frozen Backbone Training
# Only train classification head to quickly adapt to the task

experiment:
  name: "mae_vit_base_stage1_frozen"
  description: "Stage 1: MAE ViT-B/16 with frozen backbone, only training classification head"
  phase: "phase1_baseline"
  stage: 1

# Dataset Configuration - Image Split Mode
dataset:
  type: "image_split"
  train_dir: "data/train"
  val_dir: "data/val"
  test_dir: "data/test"

  image_size: 224
  batch_size: 16
  num_workers: 4

# Model Configuration - MAE ViT-B/16
# MAE is pretrained with 75% masking on ImageNet, naturally suited for occlusion tasks
model:
  type: "mae_vit_base"
  num_classes: 2
  pretrained: true
  freeze_backbone: true      # Freeze all backbone, only train head
  freeze_layers: null        # Not used when freeze_backbone=true
  drop_rate: 0.3             # Lower dropout than standard ViT (MAE is already robust)
  drop_path_rate: 0.1

# Training Configuration - Stage 1
# Goal: Fast adaptation to binary classification task
training:
  epochs: 15                 # Quick convergence expected

  optimizer:
    type: "adamw"
    lr: 1.0e-4               # Higher LR (only training head)
    weight_decay: 0.1        # Moderate regularization
    betas: [0.9, 0.999]

  scheduler:
    type: "cosine"
    warmup_epochs: 2         # Short warmup
    min_lr: 1.0e-6

  loss: "cross_entropy"

  use_amp: true
  grad_clip: 1.0

  early_stopping:
    enabled: true
    patience: 8              # Stop if no improvement for 8 epochs
    min_delta: 0.001

  checkpoint:
    save_dir: "experiments/mae_vit_base/stage1/checkpoints"
    save_best: true
    save_last: true
    save_frequency: 5
    load_from: null          # Train from scratch
    load_training_state: false

# Logging Configuration
logging:
  use_tensorboard: true
  log_dir: "experiments/mae_vit_base/stage1/logs"
  print_freq: 10

# Reproducibility
seed: 42
